---
timezone: UTC+8
---

# 一顆冬天的馬鈴薯

**GitHub ID:** Toby1009

**Telegram:** @Yunizero

## Self-introduction

馬鈴薯就是馬鈴薯

## Notes

<!-- Content_START -->
# 2026-01-15
<!-- DAILY_CHECKIN_2026-01-15_START -->
## 當AI Agent遇到Web3？

[https://hackmd.io/YjzSw1FQSR-ZE8SmKAKymA?view](https://hackmd.io/YjzSw1FQSR-ZE8SmKAKymA?view)

搞了個節錄哈

## 反思

-   是否賣東西也就要有針對AI推薦的一個呈現方式？新的SEO
    
-   如果未來機器人什麼都能做到，那就會去帶大量人力，甚至就不需要人力了。那變成擁有很多機器人才能夠生存，而沒擁有機器人的只會陷入負面循環。這時候貧富差距可能會擴大？但也許到那時候機器人會變成「公共財」，也就是大家都享用正面循環。但那時物資又會如何分配？
<!-- DAILY_CHECKIN_2026-01-15_END -->

# 2026-01-13
<!-- DAILY_CHECKIN_2026-01-13_START -->

## **Connecting Agents with A2A**

### 1\. 核心問題與解決方案

-   **痛點**：不同的 Agent（例如「客服 Agent」與「產品目錄 Agent」）通常是獨立的服務，可能由不同團隊使用不同程式語言開發，導致溝通困難。
    
-   **解法**：**A2A Protocol** 提供了一套標準，讓 Agent 能夠跨越團隊、框架和語言進行協作。
    

### 2\. 最佳適用場景

當你的系統符合以下特徵時，A2A 是最佳選擇：

-   **微服務架構 (Microservices)**：Agent 作為獨立服務運行。
    

-   **多團隊協作**：Agent 由不同團隊各自維護。
    
-   **異質環境**：需要連接使用不同語言或框架開發的 Agent。
    
-   **正式契約**：系統組件之間需要嚴謹的介面契約。
    

### 3\. ADK (Agent Development Kit) 實作方式

ADK 封裝了底層網路細節，讓開發者無需手動處理協定：

-   **服務端 (Expose)**：使用 `A2AServer` 包裝你的 Agent，讓其他 Agent 可以發現並發送請求。
    
-   **客戶端 (Consume)**：使用 `RemoteA2aAgent` 來調用遠端 Agent。它會自動處理網路通訊、身份驗證 (Auth) 和資料格式化，開發體驗就像調用本地工具一樣簡單。
    

### 4\. 快速上手：Agent Starter Pack

為了加速開發，官方提供了 **Agent Starter Pack**，內容包含：

-   **生產級代碼**：具備發現端點 (Discovery Endpoint) 的 A2A Agent。
    
-   **完整測試**：包含整合測試與負載測試。
    
-   **基礎設施代碼**：自動生成 Terraform 和 CI/CD 流程。
    
-   **可觀測性 (Observability)**：預先配置好的監控功能。
    

### 5\. 部署與資源

-   **部署目標**：支援部署至 Agent Engine 或 Google Cloud Run，使 Agent 成為可被發現的微服務。
<!-- DAILY_CHECKIN_2026-01-13_END -->

# 2026-01-12
<!-- DAILY_CHECKIN_2026-01-12_START -->


## Interactions AI

核心轉變：「對話」到「任務執行」

-   過去：傳統的LLM API (如 `generateContent`) 是「無狀態」的。開發者必須自己在客戶端（Client-side）維護對話歷史（Context Window），每次發送請求都要把過去的對話重新傳給模型。如果網路斷線或客戶端崩潰，任務就會中斷。
    
-   現在 (Stateful): Interactions API 是「有狀態」的。對話歷史、推理過程和任務進度都**儲存在 Google 的伺服器端**。這讓 AI 能夠執行跨越多個回合的複雜任務，而不需要開發者手動搬運數據。
    

兩種主要的使用場景：

-   引擎升級 (The "Engine" Upgrade) - 針對 ADK 開發者
    
    -   **操作方式：** 在 Google 的 Agent Development Kit (ADK) 中設定 `use_interactions_api=True`。
        
    -   **功能：** 這會將你的 Agent 的「大腦」（狀態管理）移至雲端。
        
    -   **解決的痛點：** **逾時 (Timeout)**。
        
        -   以前，如果一個 Agent 需要思考或執行 10 分鐘的任務，客戶端的 HTTP 連線可能會因為等待太久而斷開。
            
        -   現在，因為狀態在伺服器上，你可以實現 **"Fire-and-forget"（射後不理）** 的背景執行。你發送任務後可以斷開連接，稍後再回來查看結果，Agent 會在 Google 的後台繼續運作。
            
-   橋接模式 (The "Bridge") - 針對 A2A 協議開發者
    
    -   **操作方式：** 使用 `InteractionsApiTransport`。
        
    -   **功能：** 如果你已經有一個由多個 Agent 組成的網路（Mesh），並使用 Agent2Agent (A2A) 協議溝通，這個功能讓你將 Google 託管的 Agent（例如 **Gemini Deep Research Agent**）視為你網路中的一個「遠端節點」。
        
    -   **優勢：** 你不需要為 Google 的 Agent 寫額外的 API 包裝器（Wrapper）。你的本地 Agent 可以直接發送 A2A 訊息給 Google 的 Deep Research Agent，要求它去執行深度研究任務，然後將結果傳回給你的網路。
        

這個更新為什麼重要？

-   **卸載狀態管理 (Offload State Management)：** 開發者不再需要為了「記住對話」而在客戶端寫複雜的迴圈（Loops）或管理 Context Window 的大小。這一切由 Google 的基礎設施接手。
    
-   **非同步與背景執行 (Async/Background Execution)：** 這是實現真正「自主 Agent」的關鍵。Agent 可以在背景長時間運行（例如花 1 小時閱讀數百份文件），而不會因為前端介面關閉或網路波動而失敗。
    
-   **統一接口 (Unified Primitive)：** 透過同一個 API，你既可以使用**原始模型**（Raw Models，自己寫 Prompt），也可以直接調用 Google 訓練好的**全託管 Agent**（如 Deep Research）。
<!-- DAILY_CHECKIN_2026-01-12_END -->

# 2026-01-10
<!-- DAILY_CHECKIN_2026-01-10_START -->



## **Multimodal Agents with Gemini Live API**

Gemini建立持久WebSocket連接，創建會畫，客戶端輸入（多模態）和伺服器輸出（多模態），可以同時傳輸，可以使用ADK控制Gemini Live並為其新增功能

-   應用程式初始化：啟動時建立代理、會話服務和運行器
    
-   會話初始化：為每個連線建立會話、運行配置和即時請求佇列
    
-   雙向串流：並發的上游（客戶端→佇列）和下游（事件→客戶端）任務
    
-   優雅終止：正確清理 LiveRequestQueue 和 WebSocket 連接
    

特徵：

-   **WebSocket 通訊：** 透過 /ws/{user\_id}/{session\_id} 進行即時雙向串流傳輸
    
-   **多模態請求：** 支援文字、音訊和影像/視訊輸入，並可自動進行音訊轉錄
    
-   **靈活回應：** 文字或音訊輸出，根據模型架構自動決定。
    
-   **會話恢復：** 透過 RunConfig 設定重新連線支援
    
-   **並發任務：** 分離上游/下游非同步任務以獲得最佳效能
    
-   **互動式使用者介面：** 帶有事件控制台的 Web 介面，用於監控即時 API 事件
    
-   **Google 搜尋整合：** 代理程式配備了 google\_search 工具
    

為什麼不使用Live API？因為使用原始Live API需要負責所有事情。

Application Init -> Session Init -> Bidi-streaming Loop -> Terminate Session

-   Application Init：建構進程生命週期基礎元件，定義Agent（模型、工具及特性）、建立會話服務（開發環境使用記憶體服務，生產環境使用資料庫）、初始化運行器
    
-   Session Init：使用Websocket，要設定串流會話，獲取或建立他們的會話以恢復對話歷史紀錄。配置RunConfig以指定模式、轉錄設定和功能，建立一個新的LiveRequestQueue用於訊息緩衝。啟動run\_live()事件循環。
    
-   Bidi-streaming Loop：併發為非同步任務同時運行，上游任務透過佇列將訊息從Websocket發送到Agent，而下游任務接收來自Agent的事件，將其轉發到client，所以用戶可以在AI回應時同時發言，也可以打斷AI的發言，變成真正的雙向溝通，而不是輪流獨白。
    
-   Session Termination：當連線結束時——無論是用戶斷開連線、逾時還是發生錯誤——您都會[關閉 LiveRequestQueue](https://google.github.io/adk-docs/streaming/dev-guide/part2/#control-signals) ，會發送一個優雅的終止訊號，停止 run\_live() 循環，並確保會話狀態得以保存，以便將來恢復
<!-- DAILY_CHECKIN_2026-01-10_END -->

# 2026-01-09
<!-- DAILY_CHECKIN_2026-01-09_START -->





## Google Managed MCP

參考這篇：[Launch My Bakery: Google remote MCP demo](https://github.com/google/mcp/tree/main/examples/launchmybakery)

Google有託管式MCP，例如 BigQuery，不用去維護，而Google有原生維護MCP

```
credentials, project_id = google.auth.default(
    scopes=["https://www.googleapis.com/auth/bigquery"]
)
```

> 使用google.auth，比.env更安全

可用Apigge將自己開發的API以及外部第三方API作為Agent可發現的工具公開和管理

目前Google也將逐步為所有服務發布MCP支持，首先是：

-   Google Maps
    
-   BigQuery
    
-   Google Compute Engine（GCE）
    
-   Google Kubernetes Engine（GKE）
    

也可以透過 [Cloud API Registry](https://docs.cloud.google.com/api-registry/docs/overview) 和 [Apigee API Hub](https://docs.cloud.google.com/apigee/docs/apihub/what-is-api-hub)，開發者可以分別找到來自Google和自己組織受信任的MCP工具，並且可以透過[Google Cloud IAM](https://docs.cloud.google.com/architecture/identity) 管理存取權限 ，依靠[審計日誌實現](https://docs.cloud.google.com/logging/docs/audit)可觀測性，並利用 [Google Cloud Model Armor](https://cloud.google.com/security/products/model-armor) 防禦高級代理威脅，例如間接提示注入。
<!-- DAILY_CHECKIN_2026-01-09_END -->

# 2026-01-07
<!-- DAILY_CHECKIN_2026-01-07_START -->










## **Big Context ≠ Better Memory**

前蜜甜到，長時間運行Agent sessions會有大問題，「延遲」以及「中間遺失」問題

ADK透過Context Caching和Context Compaction解決了這些問題。

-   Context Caching：快取prompt中不可變的部分，這樣就不必在每一回合都要支付計算成本
    
-   Context Compaction：防止歷史紀錄膨脹
    

範例code中：

ContextCache：

-   min\_token：超過這prompt的才會啟動
    
-   ttl\_seconds：持續時間
    
-   cache\_intervals：間隔
    

Compaction：

-   compaction\_interval：每幾次總結
    
-   overlap\_size：重疊
    

Cmpaction會將過去訊息總結成簡潔的筆記，保留近期交流內容

![image.png](https://raw.githubusercontent.com/IntensiveCoLearning/GoogleAIAgent25Days/main/assets/Toby1009/images/2026-01-07-1767797330291-image.png)

可以將Context Compaction用於：

-   多輪debuggin sessions
    
-   Long code review agents
    
-   Document analysis with Q&A
    
-   Customer support agents
<!-- DAILY_CHECKIN_2026-01-07_END -->

# 2026-01-06
<!-- DAILY_CHECKIN_2026-01-06_START -->












## **⏪ Undo buttons for your Agents**

可以回退到之前的某個步驟，或還原到先前的狀態

有兩種：Rewind（倒帶/回溯）和Resume（恢復/續傳）兩種處理「中斷」和「錯誤」的核心機制

Resume：

-   目的：處理系統崩潰、網路斷線或等待使用者輸入
    
-   狀態變化：保持載入最後的已知狀態，繼續執行「下一步」
    
-   資料流向：向前推進
    

Rewind：

-   目的：AI走錯方向、工具報錯，或使用者想修改之前的決定
    
-   狀態變化：刪除最近得狀態變化，回到「上一步」或更早的節點
    
-   資料流向：向後跳轉
    

詳細場景與實作邏輯：

Resume：讓Agent具備「持久性」，跑到一半壞掉，或是需要等一段時間，不需要重跑流程

-   場景範例：
    
    -   IntakeAgent完成資料收集
        
    -   系統準備呼叫GapAnalysisAgent時，伺服器突然重啟
        
    -   Resume：系統重啟後，讀取資料裡的Session State，發現Intake已標記為完成，直接跳過Intake，從GapAnalysis開始執行
        
-   實作關鍵：
    
    -   Checkpoints：每完成一個步驟，就將State序列化存入資料庫
        
    -   Idempotency：確保重複執行同一個指令不會造成副作用
        

Rewind：讓Agent具備「後悔藥」或「自我修復」

-   場景範例：
    
    -   GapAnalysisAgent寫了一段Python程式碼來計算市場飽和度
        
    -   錯誤發生：執行時發現缺少了pandas套件，或計算邏輯除以零，程式崩潰
        
    -   Rewind：系統不應該繼續往下走。它需要「倒帶」回到Code Generation的前一刻，把錯誤訊息餵給LLM，讓LLM重新生成正確的程式碼
        
-   實作關鍵：
    
    -   State Truncation：必須把「錯誤路徑」上的歷史和變數清除
        
    -   Forking：有時保留錯誤紀錄作為「負面教材」，然後開始新的分支嘗試
        

Resume是為了「效率與穩定」（不做已完成的事）

Rewind是為了「準確與修正」（撤銷做錯的事）
<!-- DAILY_CHECKIN_2026-01-06_END -->

# 2026-01-05
<!-- DAILY_CHECKIN_2026-01-05_START -->















## **LLMs Can Execute Code: Autonomous Problem Solving**

啊啊啊 昨天有事就累死沒做到

LLM是機率，不夠精確，而Code則是精確的，所以會要用Code去實際計算。

這個mpa的有成功run

我仔細看了看intake\_agent蠻有趣的

為了讓Google Maps API或進行市場分析的演算法能夠看得懂我們的語句：「我想在台北開家咖啡廳」，但他們只看得`{"location":"Taipei","type":"coffee shop"}`

透過 UserRequest幫助LLM結構化成JSON

然後 after\_intake 在Agent成功執行完任務後自動觸發，這是個Callback函式，主要做「資料搬運」和「流程追蹤」，主要是stage和session的

接著就是INTAKE\_INSTRUCTION，這是system prompt，教AI如何從句子中抓出重點，提高AI精準度

為什麼UserRequest定義了欄位，還是要INTAKE\_INSTRUCTION？

主要就是雖然定義了欄位，但無法處理模糊情況！

**舉例：** 如果沒有 Instruction 裡的範例，當使用者說：「我想在**信義區**找個地方」，模型可能不知道要把「信義區」放在哪

但在 Instruction 裡寫了：

> User: “I want to open a coffee shop in **Indiranagar, Bangalore**” → target\_location: “**Indiranagar, Bangalore**”

模型就會學到：「喔！原來這種類型的詞彙（地名）要塞進 `target_location`，即便 `UserRequest` 只是說它是個字串。」

所以其實就是UserRequest告訴模型最後要「填什麼？」然後System Prompt則是告訴模型「怎麼填？」

`gap_analysis`來看看咋生code的，這會在沙盒中搞

```
code_executor=BuiltInCodeExecutor(),
```

這告訴Agent：有Python執行環境（沙盒）

雖然LLM擅長文字，但數學運算能力太爛（容易產生幻覺，例如算錯加減乘除），而有寫code能力將大大增強可信度

### 為什麼這個步驟至關重要？

假設前一個 Agent 說：「A 區有 5 家咖啡店，B 區有 2 家。」

-   **沒有 Code Executor 的 AI** 可能會說：「我覺得 B 區比較好，因為店比較少。」（憑感覺，且容易忽略人口密度）。
    
-   **有 Code Executor 的這個 Agent** 會這樣做：
    
    Python
    
    ```
    # Agent 自己寫的 Python 邏輯
    density_A = 5_shops / 10000_people
    density_B = 2_shops / 2000_people  # 假設 B 區其實很小
    if density_A < density_B:
        print("推薦 A 區，雖然店多但人更多，需求未被滿足")
    ```
    
    它能透過數學運算發現 **「反直覺」的洞察**。
    

然後在GAP\_ANALYSIS\_INSTRUCTION中也會用{}去使用之前Agent做完的填進去

## **Effective Context Management with ADK Layers**

開發Agent的本質，就是Context Engineering

Agent對於大型的任務或長期運行會有瓶頸，而讓Agent有更多的memory也就是更多的context是不可持續的。

核心問題：Context 危機

當前的開發模式面臨巨大的瓶頸，主要原因在於傳統的「附加一切 (Append-everything)」策略不可行 。

-   **成本與延遲螺旋 (Cost & Latency Spirals)**：每增加一個 Token，下一步驟的處理都會變慢且更昂貴
    
-   **模型混淆 (Model Confusion)**：出現「迷失在中間 (Lost in the middle)」現象，重要指令被大量舊資料淹沒
    
-   **物理限制 (Physical Wall)**：真實世界的任務資料量永遠會超過 Context Window 的上限
    

解決方案：情境工程 (Context Engineering)：

ADK 提出從「撰寫 Prompt」轉向「情境工程」的思維躍進 。

-   **核心隱喻**：不再將 AI 的記憶視為無限延長的逐字稿，而是視為一個「編譯過的程式 (Compiled Program)」 。
    
-   **編譯視圖 (Compiled View)**：系統像編譯器一樣，從龐大的資訊中，僅針對「當前步驟」構建出一個小型、乾淨且高度相關的指令包 。
    
-   **基礎設施化**：Context 應被視為一級系統基礎設施 (First-class system)，擁有自己的架構、規則和生命週期，就像資料庫一樣 。
    

ADK建立在三個支柱上：

-   結構(struct)：一個分層模型，將資訊的儲存方式從模型實際看的的內容分開
    
-   相依性(relevance)：擁有智慧控制系統，能夠精準判斷當下哪些資訊至關重要
    
-   當多個Agent嘗試協同工作時，如何管理Contenxt的規則
    

ADK 的架構設計 (Structure)：

ADK 的資訊架構分為四個層次，旨在分離資訊的「儲存」與 AI 實際的「可見內容」 ：

-   **工作情境 (Working Context)**：最終編譯出的 Prompt。它短小精悍、效率高，且在單次使用後即丟棄 。
    
-   **工作階段 (Session)**：完整的日誌結構，記錄發生過的所有事情 。
    
-   **記憶 (Memory)**：Agent 的長期知識庫，例如使用者偏好 。
    
-   **製品 (Artifacts)**：用於儲存大型檔案，僅透過名稱參照，而非直接貼入內容 。
    

關鍵設計模式 (Design Patterns)：

為了避免「Context 傾倒 (Context Dumping)」和「Context 爆炸 (Context Explosion)」，ADK 引入了特定模式：

-   **Handle Pattern (把手模式)**：
    
    -   針對大型資料（如 5MB 的 CSV），不直接貼入對話
        
    -   給 Agent 一個輕量的參照（Handle），例如 `report.csv`
        
    -   實際檔案僅在真正需要時才載入工作情境中
        
-   **多 Agent 協作模式 (Multi-Agent Patterns)**：
    
    -   **工具化 Agent**：將專業 Agent 視為工具，給予指令並返回結果，不共享歷史紀錄 。
        
    -   **範圍化情境 (Scoped Context)**：若需交接，僅創建並傳遞與該子任務相關的最小化歷史紀錄
        

開發者工具箱

ADK 提供了特定的物件來管理不同層級的權限與能力 ：

-   **Invocation Context**：給予 Agent 核心邏輯完全的存取權限
    
-   **Callback Context**：用於檢查流程，擁有查看和修改狀態的有限權限
    
-   **Tool Context**：賦予工具特殊能力，如搜尋記憶或處理認證
<!-- DAILY_CHECKIN_2026-01-05_END -->

# 2026-01-03
<!-- DAILY_CHECKIN_2026-01-03_START -->



















## **ADK ready in Antigravity, Gemini CLI, Cursor, Firebase Studio and more**

今天就在Antigravity中使用 `uvx agent-starter-pack create deep_search --adk` 指令，他也是幫我直接建立好，蠻讚的

他有生出一個 GEMINI.md 蠻讚的，裡面詳細的寫了如何使用Python建置、編寫和部署ADK，我等等詳細讀一下

之前有大量用過Antigravity，說一下使用心得吧，

Antigravity相較於vscode，我認為最好的點在於，會在開始之前建立task，說明之後要幹嘛，以及步驟。

這不只是讓AI能更清晰的了解要做什麼，也讓使用者了解AI會做什麼，看AI的理解跟自己的預期是否符合？

因為AI環境限制，它沒有使用者完全的資料，無法知道使用者在什麼情況下為什麼要做這些，它知道的很少，所以無法充分理解使用者意圖，因此，有這份task，對於使用者來說，能夠馬上判斷是否理解ㄧ致。

但還是可能會有誤差，所以我也會跟AI說，如果有什麼不確定的，可以直接問我，總之就是盡可能的消除資訊差。

另外，如果有Bug，也要完整的說明，要先請AI理解Bug是在什麼情況下觸發的、為什麼會要有這情況，我們程式的目的以及流程是什麼，以及架構是什麼，另外也要請AI「完整」掃描我們的架構以及Code和流程，在AI充分理解所有意圖後，成功修復的機率會提高很多，進而省掉非常多時間。

接著來說說Antigravity我覺得問題最大的點，就是他如果要執行CLI，會在chat開terminal，這跟vscode copilot不同，vscode copilot會直接在terminal上開，而Antigravity的方式常常會有bug，就是無法順利執行CLI命令，這時就要取消這步驟，並重新嘗試，或者自己在terminal上輸入，避免浪費時間，因為這步基本上就卡住了，不用期待會繼續。

現在有個名詞也叫「規格驅動開發」，就是先寫完整、詳細的規格書給AI，讓AI比較好生。

目前我也是照這方式去做，而我之後會嘗試在規格驅動開發上面再引入AI看看，也就是把我的規格丟給Gemini Pro，請他先閱讀，然後交流一番後生成很好的Prompt，再丟給Antigravity請他操作，不確定這樣能否提高準確度？
<!-- DAILY_CHECKIN_2026-01-03_END -->

# 2026-01-02
<!-- DAILY_CHECKIN_2026-01-02_START -->






















## **Production Observability**

打開了Agent Telemetry API，就能看到詳細調用的流程

![Screenshot 2026-01-02 at 10.18.17 PM.png](https://raw.githubusercontent.com/IntensiveCoLearning/GoogleAIAgent25Days/main/assets/Toby1009/images/2026-01-02-1767363662826-Screenshot_2026-01-02_at_10.18.17_PM.png)

來看一下這篇吧：[Monitoring and Observability](https://googlecloudplatform.github.io/agent-starter-pack/guide/observability.html)

![image.png](https://raw.githubusercontent.com/IntensiveCoLearning/GoogleAIAgent25Days/main/assets/Toby1009/images/2026-01-02-1767364253775-image.png)

Agent Starter Pack 提供兩種等級的可觀測性，這在檢測會蠻有用的：

-   Agent Telemetry Events(一直/強制啟動）：追蹤執行路徑、延遲、系統指標，支援所有（含LangGraph），後端服務為Cloud Trace
    
-   Prompt-Response Logging（可設定）：紀錄GenAI互動（Token用量、模型參數），僅限ADK（不支援LangGraph），後端服務為GCS->BigQuery
    

從上面來看就能知道，Telemetry主要是監測錯誤和慢的原因，而Prompot-Reponse Logging主要是監測成本以及品質。

剩下的就是在講如何配置和檢查(Prompt-Reponse Logging，可用BigQuery做查詢，想視覺話也可以將 BigQuery 遙測資料連接到 [**Looker Studio**](https://lookerstudio.google.com/) 、 [**Data Studio**](https://datastudio.google.com/) 等視覺化工具，或其他支援 BigQuery 作為資料來源的 BI 工具），以及免責說明寫說Google不會去記錄、監控這些已部署資源產生的資料，僅用來幫助使用者觀測
<!-- DAILY_CHECKIN_2026-01-02_END -->

# 2026-01-01
<!-- DAILY_CHECKIN_2026-01-01_START -->


























## 結果昨日問題 - Logs顯示不出來，長時間部署不上去

今天弄突然就有logs了，問號xdd

不過logs有個地 `Control plane operation failed due to user code: 403 Cloud Resource Manager API has not been used in project ... or it is disabled.`

這顯示我的**Cloud Resource Manager API**沒開，這是啥呢？

Vertex AI 的 SDK 在雲端啟動時，需要呼叫 **Cloud Resource Manager API** 來確認專案資訊

開啟這API也簡單，在CLI輸入`gcloud services enable cloudresourcemanager.googleapis.com` 就好

或者也可以點擊[這網誌](https://www.google.com/search?q=https://console.developers.google.com/apis/api/cloudresourcemanager.googleapis.com/overview%3Fproject%3Dmy-super-agent-2025)。

然後就再depoly就能部署成功了`make deploy`

![Screenshot 2026-01-01 at 6.15.16 PM.png](https://raw.githubusercontent.com/IntensiveCoLearning/GoogleAIAgent25Days/main/assets/Toby1009/images/2026-01-01-1767262556003-Screenshot_2026-01-01_at_6.15.16_PM.png)
<!-- DAILY_CHECKIN_2026-01-01_END -->

# 2025-12-31
<!-- DAILY_CHECKIN_2025-12-31_START -->




























## **Source-Based Deployment**

[**xinyuuum2**](https://github.com/IntensiveCoLearning/GoogleAIAgent25Days/blob/main/xinyuuum2.md)**的筆記不錯**

首先，有幾個前提，要登入google cloud、有project、有設定project id

設定project id要這樣`gcloud config set project $ProjectID`

登入google cloud要gcloud，沒有的話要先安裝，我是到 [這裡](https://docs.cloud.google.com/sdk/docs/install-sdk?hl=zh-tw) 安裝，下載，使`gcloud auth login --update-adc`登入就好了

接著運行`uvx agent-starter-pack create my-agent -a adk_base -d agent_engine` ，這邊會幫你建立好資料夾和檔案

接著cd進去`make depoly` 這部分要吐槽一下，要等一段時間
<!-- DAILY_CHECKIN_2025-12-31_END -->

# 2025-12-30
<!-- DAILY_CHECKIN_2025-12-30_START -->































## 昨天問題

昨天用adk web會讀不到yaml，而用adk run則可以

另外yaml在讀取變數時也有技巧，不過我後來就直接貼上去。

在帳單方面，發現綁卡用api key會有點貴，再試試看不綁卡會如何？感覺用flash的話應該是可以

只不過範例code有個問題，有時候search時會報錯，應該是需要等比較久。

## Gemini + ADK

之前只有用過pip或pip3，第一次用uv，速度確實快

首先，先建立一個專案要放的資料夾，`uv init` 來初始化資料夾

然後使 `uv add google-adk` 來加入google adk，接 `uv add google-genai` 這在gemini api時好用的工具

`source .venv/bin/activate.fish` 啟動虛擬環境，這是為了不用全域

`adk create my_agent` 建立agent

`.env` 裡面也要留api key

把這段丟進去 `agent.py` ，為了可以用免費的，我用 gemini 2.5 flash

```
from google.adk.agents import Agent
from google.adk.runners import Runner
from google.adk.sessions import InMemorySessionService
from google.adk.tools import google_search
from google.genai import types
import asyncio

# CONFIGURATION
APP_NAME = "simple_search_agent"
USER_ID = "user_default"
SESSION_ID = "session_01"

# AGENT DEFINITION
root_agent = Agent(
    name="search_agent",
    model="gemini-2.5-flash",
    description="A helpful assistant that can search Google.",
    instruction="""
    You are a helpful assistant with access to Google Search.
    
    If the user asks a question that requires current information or facts, use the 'google_search' tool.
    Always cite your sources implicitly by providing the answer clearly based on the search results.
    """,
    # This is the only tool enabled
    tools=[google_search],
)


# Session and Runner
async def setup_session_and_runner():
    session_service = InMemorySessionService()
    session = await session_service.create_session(
        app_name=APP_NAME, user_id=USER_ID, session_id=SESSION_ID
    )
    runner = Runner(
        agent=root_agent, app_name=APP_NAME, session_service=session_service
    )
    return session, runner


# Agent Interaction
async def call_agent_async(query):
    content = types.Content(role="user", parts=[types.Part(text=query)])
    session, runner = await setup_session_and_runner()
    events = runner.run_async(
        user_id=USER_ID, session_id=SESSION_ID, new_message=content
    )

    async for event in events:
        if event.is_final_response():
            final_response = event.content.parts[0].text
            print("Agent Response: ", final_response)


if __name__ == "__main__":
    asyncio.run(call_agent_async("what's the latest ai news?"))
```

從code來看可以發現分三部分：

-   Agent，這部分負責定義agent，跟昨天的yaml很像，instruction就是system prompt，tool就是可以用的工具，而這code用的工具是google搜尋
    
-   setup\_session\_and\_runner,讓AI記得之前的對話，所以要管理session
    
    -   `InMemorySessionService`是個臨時的資料庫
        
    -   `Runner`: 它是代理人的「身體」，負責串接 `Agent` 與 `Session`，處理實際的運行邏輯
        
-   call\_agent\_async：非同步執行邏輯
    
    -   `runner.run_async`: 這是非同步執行方法。它不會一次性回傳結果，而是回傳一個 **Event Stream (事件流)**。
        
    -   事件處理:
        
        -   在執行過程中，代理人可能會產生多個事件（例如：決定要搜尋、搜尋中、生成文字）。
            
        -   `if event.is_final_response()`: 程式碼會遍歷所有事件，直到找到最後一個「最終回應」的事件，並將結果印出來。
<!-- DAILY_CHECKIN_2025-12-30_END -->

# 2025-12-29
<!-- DAILY_CHECKIN_2025-12-29_START -->

































## 使用YAML來玩Agent

複製貼上範例就能玩啦：

```
uvx --from google-adk adk create --type=config my_agent
uvx --from google-adk adk web my_agent/
```

這邊有兩個部分，一個部分是使用google-adk用adk create指令弄一個my\_agent的模板

然後，使用adk web打開my\_agent

這時畫面就會出現UI介面，可以問問題

![Screenshot 2025-12-29 at 4.06.20 PM.png](https://raw.githubusercontent.com/IntensiveCoLearning/GoogleAIAgent25Days/main/assets/Toby1009/images/2025-12-29-1766995592813-Screenshot_2025-12-29_at_4.06.20_PM.png)

然後也有玩了一下連接mcp來抓取網頁資料，這就是把Agent裝上手！

-   root\_agent.yaml：
    

```
name: web_research_coordinator
model: gemini-2.5-flash
description: 'A coordinator agent that manages web research using Firecrawl for scraping and two specialized sub-agents for research and summarization.'
instruction: |
  You are a web research coordinator agent. Your job is to:
  1. Coordinate web research tasks using two sub-agents:
     - research_agent: Handles web search and scraping using the Firecrawl MCP tool, and analyzes content for insights and patterns
     - summary_agent: Creates comprehensive summaries and reports
  2. Synthesize findings from both agents into actionable insights
  Important: When delegating to research_agent, provide clear, specific instructions:
  For URLs: "Please scrape and analyze the content from [URL]"
  For research topics: "Please search for and analyze information about [TOPIC]"
  Do NOT pass complex objects or arrays to the research_agent. Use simple, clear text instructions.
  When given a URL or research topic:
  - Pass a clear, simple instruction to the research_agent (e.g., "Scrape and analyze https://example.com" or "Research AI trends")
  - The research_agent will use appropriate Firecrawl tools with correct parameters
  - The research_agent will analyze the content and return key findings
  - Delegate summarization of the research_agent's analysis to the summary_agent
  - Combine outputs from both agents into a final comprehensive report
sub_agents:
  - config_path: research_agent.yaml
  - config_path: summary_agent.yaml\
```

-   research\_agent.yaml
    

```
# yaml-language-server: $schema=https://raw.githubusercontent.com/google/adk-python/refs/heads/main/src/google/adk/agents/config_schemas/AgentConfig.json
name: research_agent
model: gemini-2.5-flash
description: 'Specialized agent for analyzing web content and extracting insights, patterns, and key information.'
instruction: |
  You are a research analysis agent with access to Firecrawl web scraping tools. Your job is to:
  1. Use Firecrawl tools to scrape and search web content
  2. Analyze scraped content for key insights and patterns
  3. Identify important facts, trends, and relationships
  4. Extract relevant quotes and data points
  5. Provide structured analysis of the content
  6. Highlight any inconsistencies or gaps in information
  Firecrawl Tool Usage:
  - For URLs: Use `firecrawl_scrape` with parameter: {"url": "https://example.com"}
  - For search queries: Use `firecrawl_search` with parameter: {"query": "search term"}
  - Always use simple object parameters, not arrays or complex structures

  Always provide your analysis in a structured format with clear sections for:
  - Key Findings
  - Important Data Points
  - Trends and Patterns
  - Notable Quotes
  - Areas for Further Investigation
tools:
  - name: MCPToolset
    args:
      stdio_server_params:
        command: "npx"
        args:
          - "-y"
          - "firecrawl-mcp"
        env:
          FIRECRAWL_API_KEY: "${FIRECRAWL_API_KEY}"
```

-   summary\_agent.yaml
    

```
name: summary_agent
model: gemini-2.5-flash
description: 'Specialized agent for creating comprehensive summaries and reports from research findings.'
instruction: |
  You are a summarization agent. Your job is to:
  1. Create clear, concise summaries of research findings
  2. Organize information into logical sections
  3. Generate executive summaries for quick understanding
  4. Create detailed reports with proper formatting
  5. Ensure all important information is captured and presented clearly
  Always structure your output with:
  - Executive Summary (2-3 sentences)
  - Detailed Summary (organized by topic)
  - Key Takeaways (bullet points)
  - Recommendations (if applicable)
  When creating summaries, ensure:
  - Information is accurate and well-organized
  - Key points are highlighted and easy to find
  - Complex information is simplified without losing meaning
  - Recommendations are actionable and specific
  - The summary is comprehensive yet concise
```

弄完會長這樣

![Screenshot 2025-12-29 at 4.15.04 PM.png](https://raw.githubusercontent.com/IntensiveCoLearning/GoogleAIAgent25Days/main/assets/Toby1009/images/2025-12-29-1766996154303-Screenshot_2025-12-29_at_4.15.04_PM.png)

其`FIRECRAWL_API_KEY` 要填在.env檔案裡面，在.env也會看`GOOGLE_API_KEY`

這兩個Key都是要註冊的，`GOOGLE_API_KEY` 是在Google AI Studio那邊註冊，免費的有限制，不太能用，我是綁U卡。

`FIRECRAWL_API_KEY` 則是去Firecrawl註冊，這是MCP的API KEY

什麼是YAML？

是一個輕量級的標記語言，優於XML和JSON，使用縮排和簡潔語法，強調數據層次結構

常用於配置文件和數據交換

從前面幾個文件中可以看到：

name定義了這個名稱

model：定義了使用啥模型

description：名片，簡要說明agent的職責與專長

instruction：agent的操作手冊，定義agent的邏輯與約束，也就是我們常說的system prompt

sub\_agents：告訴有哪些子agent

tool：定義了agent可以調用外部功能，要在instruction中告訴agent「何時」以及「如何」使用這些tools

有一個有趣的點是，agent在跑時也會跑pro，明明yaml設定的是2.5flash！

喔喔 發現是因為沒正確連到yaml

不知道為什麼用adk web連不到，但adk run可以（cli模式）
<!-- DAILY_CHECKIN_2025-12-29_END -->

# 2025-12-28
<!-- DAILY_CHECKIN_2025-12-28_START -->







































## 閱讀《Introduction to Agetns》

今天看了《[**Introduction to Agents**](https://www.kaggle.com/whitepaper-introduction-to-agents) **》**

裡面講了AI Agent的架構，需要注意的，以及企業該如何搞

一開始會有人問？有了AI，幹嘛還要AI Agent，AI Agent是啥？

原本的AI僅為預測或創建內容的AI，而AI Agent轉變為一種新的能夠自主解決問題和執行任務的軟體類別。

處理複雜、多步驟任務，這些任務單獨由模型無法完成，最關鍵的能力在於，Agent可以單獨工作，找出達成目標所需的下一步驟，不需要在每個部分都要有人指導他們。

這篇文章提供了全面的基礎，告訴我們：

-   核心結構：將代理分成基本的組成部分
    
    -   推理模型
        
    -   可執行工具
        
    -   治理的協調層
        
-   能力分類：代理從簡單的、連接問題解決者->複雜的、協作多元代理系統
    
-   架構設計：深入探討每個組成部分的實際設計考量，從模型選擇到工具實現
    
-   建立生產建置：建立頻估、debug、安全，和擴展agentic systems，從單一實例到企業治理
    

基本組成部分分類為：

-   推理模型（大腦）：也就是讓他具備跟人類一樣能夠「推理」、「思考」、「處理資訊」，也是整個架構的核心
    
-   可執行工具（手）：要能夠抓取世界，跟真實世界做互動（API、資料庫、搜尋引擎等），讓代理能夠具備行動能力。
    
-   協調層（神經系統）：管理規劃、記憶（狀態）與推理策略的執行流程。總之就是負責規劃與流程的。
    
-   部署（身體和腳）：將 Agent 託管於伺服器，使其成為可擴展、安全的服務。
    

核心思維轉變：

-   **從磚匠變導演**：傳統開發者像「磚匠」，精確定義邏輯步驟；Agent 開發者則像「導演」，設定場景（指令）、選擇演員（工具）並提供背景（數據）。
    
-   **上下文工程 (Context Engineering)**：從prompt engineering -> context engineering。這被視為 Agent 開發的核心，旨在透過精確管理模型的注意力來達成目標 。
    

Context Engineering很重要，我記得最近Claude也推出了Skills，就是在搞這問題：[agentskills](https://agentskills.io/home)

核心來說，代理運作在一個持續循環的過程來達成任務：

1.  獲取任務：流程由一個具體、高層次的目標啟動，任務可能由使用者提供，也可能由自動觸發器觸發（例如，收到新的高優先客戶工單）
    
2.  掃描/描述場景：智能體感知其環境以收集上下文資訊。「使用者的情球是什麼？說了什麼？」、「我的短期記憶中有什麼訊息？我是否已經嘗試過執行此任務？用戶上週是否提供給我指導？」、「我可以從我的工具（例如日曆、資料庫或者API）中存取哪些內容？」
    
3.  思考：這是代理的核心「思考」循環，由推理模型驅動。代理分析任務（步驟1）與場景（步驟2），並制定計劃。這是一系列推理：「要預定行程，首先需要知道團隊成員有哪些。將使用啥工具，然後幹嘛等等」
    
4.  執行動作：編排執行計劃的一個具體步驟。選擇合適的呼叫工具，這是代理自身內部推理之外對外在世界採取行動。
    
5.  觀察與迭代：代理觀察期操作的結果，然後繼續循環下一步。
    

![Screenshot 2025-12-28 at 3.59.40 PM.png](https://raw.githubusercontent.com/IntensiveCoLearning/GoogleAIAgent25Days/main/assets/Toby1009/images/2025-12-28-1766908796355-Screenshot_2025-12-28_at_3.59.40_PM.png)

接著將Agent系統分個等級（Taxonomy）：

-   Level 0（核心推理系統）：純模型，依賴訓練數據，無即時資訊，優勢在於很好解釋「既定的概念」
    
-   Level 1（連接型問題解決者）：具備工具使用能力（如RAG或搜尋API），可獲取即時數據，也是架構中的「手」，解決的不再只是靜態問題，而是擁有連結世界的能力。
    
-   Level 2（戰略型問題解決者）：能處理複雜、多步驟的計畫與情境工程（Context Engineering），可以提供多樣化複雜的主動任務。
    
-   Level 3（協作式多代理系統）：像人類組織一樣，由不同專業的Agent組成團隊協作。
    
-   Level 4（自我演進系統）：能識別自身能力差距，自主建立新工具或新Agent
    

![Screenshot 2025-12-28 at 5.50.49 PM.png](https://raw.githubusercontent.com/IntensiveCoLearning/GoogleAIAgent25Days/main/assets/Toby1009/images/2025-12-28-1766915467088-Screenshot_2025-12-28_at_5.50.49_PM.png)

為啥要給Agent系統分等級？主要是為了讓開發者、架構師或產品負責人在面對複雜技術環境時，能有一套標準化的框架來進行決策與規劃。總之就是知道系統架構該如何建構、演進以及管理。

有一個有意思的點是做出「超級代理」沒那麼高效，採用「專家團隊」的方法比較好，與人類組織相似，將複雜任務接割成子任務，每個任務都分配給專門的、專業的AI Agent。

![Screenshot 2025-12-28 at 5.51.26 PM.png](https://raw.githubusercontent.com/IntensiveCoLearning/GoogleAIAgent25Days/main/assets/Toby1009/images/2025-12-28-1766915543600-Screenshot_2025-12-28_at_5.51.26_PM.png)

Vertex AI Agent Engine支援Runtime和平台上的所有其他內容。

![Screenshot 2025-12-28 at 5.54.21 PM.png](https://raw.githubusercontent.com/IntensiveCoLearning/GoogleAIAgent25Days/main/assets/Toby1009/images/2025-12-28-1766915681745-Screenshot_2025-12-28_at_5.54.21_PM.png)

在測試方面，不同於傳統軟體開發的測試方式：Devops、MLOps、GenAIOps

AgentOps（不可預測的結構化方式）將不可預測性從一個弱點，轉變成受管理、可衡量且可靠的點。（主要是Agent具備隨機性，需要不同方式）是DevOps和MLOps的演變

![Screenshot 2025-12-28 at 4.34.03 PM.png](https://raw.githubusercontent.com/IntensiveCoLearning/GoogleAIAgent25Days/main/assets/Toby1009/images/2025-12-28-1766910851636-Screenshot_2025-12-28_at_4.34.03_PM.png)

有以下幾種衡量與方式解：

-   衡量重要因素（KPI），就像A/B測試那樣，要讓Agent知道啥是更好？好的標準是啥？
    
-   品質不適用「正確」或「失敗」決定，使用LM Judge
    
-   指標驅動開發
    
-   使用OpenTelemetry Traces來debug
    
-   珍惜人類反饋，像是使用者提交的錯誤報告，或者倒讚啥的，來建立一個新的、永久的測試案例
    

AI要有用，很直覺的就是給予對方Power/權利，但也增加了風險，所以不能僅僅依賴AI模型的判斷，因為它可以被提示注入等技術所操縱，最好的方式是混合式、防禦式的深度方法。

-   第一層：傳統、確定的守護欄組成 - 一組硬編碼的規則，作為模型推理之外的保安瓶頸。可能是一個政策引擎，可阻止任何超過$100的購買，或需要在代理與外部API互動前取得用戶明確確認。這層提供可預測、可審計。給代理權利硬性限制。
    
-   第二層利用基準推論防禦，使用AI來保護AI。這包括訓練模型使其更能抵抗攻擊（對抗性訓練）以及使用，更小、專業化的「保護模型」，這些模型可以在執行前所提出的激化，標示出潛在的高風險或違反政策的步驟，以供審查。
    

在傳統的安全模型中，有人類使用者可能會使用OAuth或SSO，也有使用IAM或服務帳戶的服務。

代理人增加了第三類原則。 代理不僅僅是一個程式；它是一個自主的行為者，一種需要自己可驗證身份的新型原則。 就像向員工發放身份證一樣，平臺上的每個代理都必須獲得安全、可驗證的「數字護照」。 這位代理人身份與呼叫它的使用者和構建它的開發人員的身份不同。 這是我們必須如何處理企業身份和訪問管理（IAM）的根本性轉變。

細緻的顆粒度是必須的，不然造成的破壞性很大，讓我想到之前的「[**Google Antigravity just deleted the contents of my whole drive.**](https://www.reddit.com/r/google_antigravity/comments/1p82or6/google_antigravity_just_deleted_the_contents_of/)」

![Screenshot 2025-12-28 at 4.48.08 PM.png](https://raw.githubusercontent.com/IntensiveCoLearning/GoogleAIAgent25Days/main/assets/Toby1009/images/2025-12-28-1766911695427-Screenshot_2025-12-28_at_4.48.08_PM.png)

利用限制訪問的策略 ：

策略是一種授權形式（AuthZ），與身份驗證（AuthN）不同。 通常，策略限制了委託人的能力；例如，「營銷使用者只能訪問這27個API端點，不能執行刪除命令。」 當我們開發代理時，我們需要對代理、他們的工具、其他內部代理、他們可以共享的上下文和遠端代理應用許可權。 這樣想：如果您將所有API、資料、工具和代理新增到系統中，那麼您必須限制對完成工作所需的功能的子集的訪問。 這是建議的方法：應用最小特權原則，同時保持上下文相關性。

ADK Agent的安全：

隨著身份和政策的核心原則的確立，保護使用代理開發工具包（ADK）構建的代理成為透過程式和配置應用這些概念的實際練習。 如上所述，該過程需要明確定義身份：使用者帳戶（例如OAuth）、服務帳戶（執行程式）、代理身份（使用授權）。 身份驗證處理完畢後，下一層防禦涉及建立政策來限制對服務的訪問。 這通常在API治理層完成，以及支援MCP和A2A服務的治理。 下一層是在您的工具、模型和子代理中構建護欄，以執行策略。 這確保了無論LM的原因或惡意提示可能暗示什麼，工具本身的邏輯都會拒絕執行不安全或非策略的操作。 這種方法提供了一個可預測和可審計的安全基線，將抽象的安全策略轉化為具體、可靠的程式。

![Screenshot 2025-12-28 at 4.57.35 PM.png](https://raw.githubusercontent.com/IntensiveCoLearning/GoogleAIAgent25Days/main/assets/Toby1009/images/2025-12-28-1766912263121-Screenshot_2025-12-28_at_4.57.35_PM.png)

如果正在建立一兩個代理，那關心的在於安全;如果正在建立許多代理，那必須設計系統來處理。

這就是量變引起的質變（Ｘ

Agent本身也是一個新的攻擊向量，惡意者可以嘗試提示詞注入來劫代理程式，或數據中毒來損毀它用於訓練貨RAG的信息。

如果Agent的限制不夠嚴格，可能會無意中在其回應中洩漏敏感客戶資訊或專有信息。

需要提供深度防禦策略減輕風險，確保企業專有信息不會用於訓練基礎模型，並且受到像VPC服務控制這樣的保護，對輸入和輸出過濾，並且提供契約保障，例如對於訓練數據和知識產權的賠償。

需要有個維護交通的，提供所有代理城市交通使用

代理程式對工具的呼叫（透過MCP），代理程式之間的合作（透過A2A），以及直接對LM的推論請求。

透過位於這個關鍵的交匯點，一個組織可以檢查、路由、監控和管理每一個互動。

-   執行政策時執行：作為實施架構的瓶頸安全性。負責處理驗證和授權。集中執行提供了一個「單一視窗」，這將和互不相關的代理程式和工作流程轉變為透明且可核閱的系統。
    
-   中央集權管理：為了有效執行政策，閘道需要一個事實來源。這由中央登記表提供-一個用於代理程式的企業應用商店。此登記能夠發現並重用現有資產，防止重複性工作，同時提供管理完整的清單。
    

更重要的是，它讓代理程式和工具擁有正式的生命週期，允許在發布前進行安全審查、版本控制，以及建立細粒度的政策來規定哪些營運單位可以存取哪些代理。

企業及代理必須同時可靠且具有成本效益

一個代理的表現會隨時間退化-被稱為「老化」，導致效用和信任損失。（老化有可能是過時或者Context windows太多，這也是Claude Skills有提到要解決的）

手動更新一個龐大的代理陣列以跟上這些變化是不經濟且換慢的，更好的方式是設定可以自學和進化的agent，透過最少的工程努力來提高他們的工作品質。

如何自我進化？

學習過程由多種資訊來源驅動：

-   執行時經驗：代理從執行時產生的工作中學習，例如會畫紀錄，痕跡，以及記憶，他們捕捉成功、失敗、工具互動和決策。
    
-   外部信號：例如更新的企業政策、公共監管指南或其他代理人的批評
    

最成功的適應技術可分為兩種類別：

-   增強情境工程：系統持續改進其提示、少樣本範例，以及從記憶中取得的資訊。
    
-   工具優化和創造：代理的推理能識別其能力並行動以填補他們。
    

整理一下生產環境下的幾點關鍵考量：

-   **Agent Ops**：因 Agent 具備隨機性，傳統測試不再適用，需導入「LM 評審 (LM as Judge)」與 OpenTelemetry 追蹤來確保質量 。
    
-   **安全性 (Security)**：採「防禦深度」策略，結合傳統硬性護欄（Hardcoded rules）與 AI 輔助防禦（如 Model Armor）。
    
-   **身分識別 (Identity)**：為 Agent 建立獨立的數位身分（如 SPIFFE 標準），並實施最小權限原則 。
    
-   **互操作性 (Interoperability)**：透過 **A2A 協定**（Agent-to-Agent）讓不同團隊開發的專業 Agent 能夠標準化地溝通與發現 。
    

目前的前沿範例：

-   **Google Co-Scientist**：由多代理組成的生態系統，用於加速科學研究、產生並評估科學假設 。
    
-   **AlphaEvolve**：能夠自主發現並優化數學與計算機科學演算法的系統 。
    
-   **Agent Gym**：一個離線的模擬環境，讓 Agent 在不影響生產環境的情況下進行試錯與學習優化 。
    

## 安裝環境啥的

先來看看有啥資源好了：

-   [Agent Development Kit（ADK）](https://google.github.io/adk-docs/)：ADK是一個靈活、模塊化的框架，主要用於開發與部署AI Agent
    
-   [ADK中文文檔](https://adk.wiki/)
    
-   [Advent of Agents 2025官網](https://adventofagents.com/)
    
-   [Advent of Agents 2025大神筆記](https://github.com/anxiong2025/25-Day-Agents-Course-by-Google?tab=readme-ov-file)
    
-   [Vertex AI Agent Engine](https://docs.cloud.google.com/agent-builder/agent-engine/overview)：是Vertex AI平台的一部分，讓開發人員在正式環境中部署、管理及調度 AI 代理，Agent Engine 會處理基礎架構，以便在正式環境中調度代理，讓您專心打造應用程式。
    
-   [agent-starter-pack](https://github.com/GoogleCloudPlatform/agent-starter-pack)：**一個 Python 包，為 Google Cloud 上的 GenAI 代理提供**生產就緒模板，\*\*專注於您的代理邏輯—入門包提供了其他一切：基礎架構、CI/CD、可觀測性和安全性。
    
-   [Google Codelab](https://codelabs.developers.google.com/?hl=zh-tw)：Google Developers Codelabs 提供引導式教學課程，讓您親身體驗程式設計。大多數程式碼研究室都會逐步引導您建構小型應用程式，或者為現有應用程式新增功能
    
-   [Advent of Agents 2025我的中文翻譯Notion](https://www.notion.so/Google-25-AI-Agent-2d26fba5a2d38037ad5dcb5141935cc2?source=copy_link)
<!-- DAILY_CHECKIN_2025-12-28_END -->
<!-- Content_END -->
