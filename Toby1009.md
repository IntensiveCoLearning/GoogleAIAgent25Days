---
timezone: UTC+8
---

# 一顆冬天的馬鈴薯

**GitHub ID:** Toby1009

**Telegram:** @Yunizero

## Self-introduction

馬鈴薯就是馬鈴薯

## Notes

<!-- Content_START -->
# 2026-01-01
<!-- DAILY_CHECKIN_2026-01-01_START -->
## 結果昨日問題 - Logs顯示不出來，長時間部署不上去

今天弄突然就有logs了，問號xdd

不過logs有個地 `Control plane operation failed due to user code: 403 Cloud Resource Manager API has not been used in project ... or it is disabled.`

這顯示我的**Cloud Resource Manager API**沒開，這是啥呢？

Vertex AI 的 SDK 在雲端啟動時，需要呼叫 **Cloud Resource Manager API** 來確認專案資訊

開啟這API也簡單，在CLI輸入`gcloud services enable cloudresourcemanager.googleapis.com` 就好

或者也可以點擊[這網誌](https://www.google.com/search?q=https://console.developers.google.com/apis/api/cloudresourcemanager.googleapis.com/overview%3Fproject%3Dmy-super-agent-2025)。

然後就再depoly就能部署成功了`make deploy`

![Screenshot 2026-01-01 at 6.15.16 PM.png](https://raw.githubusercontent.com/IntensiveCoLearning/GoogleAIAgent25Days/main/assets/Toby1009/images/2026-01-01-1767262556003-Screenshot_2026-01-01_at_6.15.16_PM.png)
<!-- DAILY_CHECKIN_2026-01-01_END -->

# 2025-12-31
<!-- DAILY_CHECKIN_2025-12-31_START -->


## **Source-Based Deployment**

[**xinyuuum2**](https://github.com/IntensiveCoLearning/GoogleAIAgent25Days/blob/main/xinyuuum2.md)**的筆記不錯**

首先，有幾個前提，要登入google cloud、有project、有設定project id

設定project id要這樣`gcloud config set project $ProjectID`

登入google cloud要gcloud，沒有的話要先安裝，我是到 [這裡](https://docs.cloud.google.com/sdk/docs/install-sdk?hl=zh-tw) 安裝，下載，使`gcloud auth login --update-adc`登入就好了

接著運行`uvx agent-starter-pack create my-agent -a adk_base -d agent_engine` ，這邊會幫你建立好資料夾和檔案

接著cd進去`make depoly` 這部分要吐槽一下，要等一段時間
<!-- DAILY_CHECKIN_2025-12-31_END -->

# 2025-12-30
<!-- DAILY_CHECKIN_2025-12-30_START -->





## 昨天問題

昨天用adk web會讀不到yaml，而用adk run則可以

另外yaml在讀取變數時也有技巧，不過我後來就直接貼上去。

在帳單方面，發現綁卡用api key會有點貴，再試試看不綁卡會如何？感覺用flash的話應該是可以

只不過範例code有個問題，有時候search時會報錯，應該是需要等比較久。

## Gemini + ADK

之前只有用過pip或pip3，第一次用uv，速度確實快

首先，先建立一個專案要放的資料夾，`uv init` 來初始化資料夾

然後使 `uv add google-adk` 來加入google adk，接 `uv add google-genai` 這在gemini api時好用的工具

`source .venv/bin/activate.fish` 啟動虛擬環境，這是為了不用全域

`adk create my_agent` 建立agent

`.env` 裡面也要留api key

把這段丟進去 `agent.py` ，為了可以用免費的，我用 gemini 2.5 flash

```
from google.adk.agents import Agent
from google.adk.runners import Runner
from google.adk.sessions import InMemorySessionService
from google.adk.tools import google_search
from google.genai import types
import asyncio

# CONFIGURATION
APP_NAME = "simple_search_agent"
USER_ID = "user_default"
SESSION_ID = "session_01"

# AGENT DEFINITION
root_agent = Agent(
    name="search_agent",
    model="gemini-2.5-flash",
    description="A helpful assistant that can search Google.",
    instruction="""
    You are a helpful assistant with access to Google Search.
    
    If the user asks a question that requires current information or facts, use the 'google_search' tool.
    Always cite your sources implicitly by providing the answer clearly based on the search results.
    """,
    # This is the only tool enabled
    tools=[google_search],
)


# Session and Runner
async def setup_session_and_runner():
    session_service = InMemorySessionService()
    session = await session_service.create_session(
        app_name=APP_NAME, user_id=USER_ID, session_id=SESSION_ID
    )
    runner = Runner(
        agent=root_agent, app_name=APP_NAME, session_service=session_service
    )
    return session, runner


# Agent Interaction
async def call_agent_async(query):
    content = types.Content(role="user", parts=[types.Part(text=query)])
    session, runner = await setup_session_and_runner()
    events = runner.run_async(
        user_id=USER_ID, session_id=SESSION_ID, new_message=content
    )

    async for event in events:
        if event.is_final_response():
            final_response = event.content.parts[0].text
            print("Agent Response: ", final_response)


if __name__ == "__main__":
    asyncio.run(call_agent_async("what's the latest ai news?"))
```

從code來看可以發現分三部分：

-   Agent，這部分負責定義agent，跟昨天的yaml很像，instruction就是system prompt，tool就是可以用的工具，而這code用的工具是google搜尋
    
-   setup\_session\_and\_runner,讓AI記得之前的對話，所以要管理session
    
    -   `InMemorySessionService`是個臨時的資料庫
        
    -   `Runner`: 它是代理人的「身體」，負責串接 `Agent` 與 `Session`，處理實際的運行邏輯
        
-   call\_agent\_async：非同步執行邏輯
    
    -   `runner.run_async`: 這是非同步執行方法。它不會一次性回傳結果，而是回傳一個 **Event Stream (事件流)**。
        
    -   事件處理:
        
        -   在執行過程中，代理人可能會產生多個事件（例如：決定要搜尋、搜尋中、生成文字）。
            
        -   `if event.is_final_response()`: 程式碼會遍歷所有事件，直到找到最後一個「最終回應」的事件，並將結果印出來。
<!-- DAILY_CHECKIN_2025-12-30_END -->

# 2025-12-29
<!-- DAILY_CHECKIN_2025-12-29_START -->







## 使用YAML來玩Agent

複製貼上範例就能玩啦：

```
uvx --from google-adk adk create --type=config my_agent
uvx --from google-adk adk web my_agent/
```

這邊有兩個部分，一個部分是使用google-adk用adk create指令弄一個my\_agent的模板

然後，使用adk web打開my\_agent

這時畫面就會出現UI介面，可以問問題

![Screenshot 2025-12-29 at 4.06.20 PM.png](https://raw.githubusercontent.com/IntensiveCoLearning/GoogleAIAgent25Days/main/assets/Toby1009/images/2025-12-29-1766995592813-Screenshot_2025-12-29_at_4.06.20_PM.png)

然後也有玩了一下連接mcp來抓取網頁資料，這就是把Agent裝上手！

-   root\_agent.yaml：
    

```
name: web_research_coordinator
model: gemini-2.5-flash
description: 'A coordinator agent that manages web research using Firecrawl for scraping and two specialized sub-agents for research and summarization.'
instruction: |
  You are a web research coordinator agent. Your job is to:
  1. Coordinate web research tasks using two sub-agents:
     - research_agent: Handles web search and scraping using the Firecrawl MCP tool, and analyzes content for insights and patterns
     - summary_agent: Creates comprehensive summaries and reports
  2. Synthesize findings from both agents into actionable insights
  Important: When delegating to research_agent, provide clear, specific instructions:
  For URLs: "Please scrape and analyze the content from [URL]"
  For research topics: "Please search for and analyze information about [TOPIC]"
  Do NOT pass complex objects or arrays to the research_agent. Use simple, clear text instructions.
  When given a URL or research topic:
  - Pass a clear, simple instruction to the research_agent (e.g., "Scrape and analyze https://example.com" or "Research AI trends")
  - The research_agent will use appropriate Firecrawl tools with correct parameters
  - The research_agent will analyze the content and return key findings
  - Delegate summarization of the research_agent's analysis to the summary_agent
  - Combine outputs from both agents into a final comprehensive report
sub_agents:
  - config_path: research_agent.yaml
  - config_path: summary_agent.yaml\
```

-   research\_agent.yaml
    

```
# yaml-language-server: $schema=https://raw.githubusercontent.com/google/adk-python/refs/heads/main/src/google/adk/agents/config_schemas/AgentConfig.json
name: research_agent
model: gemini-2.5-flash
description: 'Specialized agent for analyzing web content and extracting insights, patterns, and key information.'
instruction: |
  You are a research analysis agent with access to Firecrawl web scraping tools. Your job is to:
  1. Use Firecrawl tools to scrape and search web content
  2. Analyze scraped content for key insights and patterns
  3. Identify important facts, trends, and relationships
  4. Extract relevant quotes and data points
  5. Provide structured analysis of the content
  6. Highlight any inconsistencies or gaps in information
  Firecrawl Tool Usage:
  - For URLs: Use `firecrawl_scrape` with parameter: {"url": "https://example.com"}
  - For search queries: Use `firecrawl_search` with parameter: {"query": "search term"}
  - Always use simple object parameters, not arrays or complex structures

  Always provide your analysis in a structured format with clear sections for:
  - Key Findings
  - Important Data Points
  - Trends and Patterns
  - Notable Quotes
  - Areas for Further Investigation
tools:
  - name: MCPToolset
    args:
      stdio_server_params:
        command: "npx"
        args:
          - "-y"
          - "firecrawl-mcp"
        env:
          FIRECRAWL_API_KEY: "${FIRECRAWL_API_KEY}"
```

-   summary\_agent.yaml
    

```
name: summary_agent
model: gemini-2.5-flash
description: 'Specialized agent for creating comprehensive summaries and reports from research findings.'
instruction: |
  You are a summarization agent. Your job is to:
  1. Create clear, concise summaries of research findings
  2. Organize information into logical sections
  3. Generate executive summaries for quick understanding
  4. Create detailed reports with proper formatting
  5. Ensure all important information is captured and presented clearly
  Always structure your output with:
  - Executive Summary (2-3 sentences)
  - Detailed Summary (organized by topic)
  - Key Takeaways (bullet points)
  - Recommendations (if applicable)
  When creating summaries, ensure:
  - Information is accurate and well-organized
  - Key points are highlighted and easy to find
  - Complex information is simplified without losing meaning
  - Recommendations are actionable and specific
  - The summary is comprehensive yet concise
```

弄完會長這樣

![Screenshot 2025-12-29 at 4.15.04 PM.png](https://raw.githubusercontent.com/IntensiveCoLearning/GoogleAIAgent25Days/main/assets/Toby1009/images/2025-12-29-1766996154303-Screenshot_2025-12-29_at_4.15.04_PM.png)

其`FIRECRAWL_API_KEY` 要填在.env檔案裡面，在.env也會看`GOOGLE_API_KEY`

這兩個Key都是要註冊的，`GOOGLE_API_KEY` 是在Google AI Studio那邊註冊，免費的有限制，不太能用，我是綁U卡。

`FIRECRAWL_API_KEY` 則是去Firecrawl註冊，這是MCP的API KEY

什麼是YAML？

是一個輕量級的標記語言，優於XML和JSON，使用縮排和簡潔語法，強調數據層次結構

常用於配置文件和數據交換

從前面幾個文件中可以看到：

name定義了這個名稱

model：定義了使用啥模型

description：名片，簡要說明agent的職責與專長

instruction：agent的操作手冊，定義agent的邏輯與約束，也就是我們常說的system prompt

sub\_agents：告訴有哪些子agent

tool：定義了agent可以調用外部功能，要在instruction中告訴agent「何時」以及「如何」使用這些tools

有一個有趣的點是，agent在跑時也會跑pro，明明yaml設定的是2.5flash！

喔喔 發現是因為沒正確連到yaml

不知道為什麼用adk web連不到，但adk run可以（cli模式）
<!-- DAILY_CHECKIN_2025-12-29_END -->

# 2025-12-28
<!-- DAILY_CHECKIN_2025-12-28_START -->













## 閱讀《Introduction to Agetns》

今天看了《[**Introduction to Agents**](https://www.kaggle.com/whitepaper-introduction-to-agents) **》**

裡面講了AI Agent的架構，需要注意的，以及企業該如何搞

一開始會有人問？有了AI，幹嘛還要AI Agent，AI Agent是啥？

原本的AI僅為預測或創建內容的AI，而AI Agent轉變為一種新的能夠自主解決問題和執行任務的軟體類別。

處理複雜、多步驟任務，這些任務單獨由模型無法完成，最關鍵的能力在於，Agent可以單獨工作，找出達成目標所需的下一步驟，不需要在每個部分都要有人指導他們。

這篇文章提供了全面的基礎，告訴我們：

-   核心結構：將代理分成基本的組成部分
    
    -   推理模型
        
    -   可執行工具
        
    -   治理的協調層
        
-   能力分類：代理從簡單的、連接問題解決者->複雜的、協作多元代理系統
    
-   架構設計：深入探討每個組成部分的實際設計考量，從模型選擇到工具實現
    
-   建立生產建置：建立頻估、debug、安全，和擴展agentic systems，從單一實例到企業治理
    

基本組成部分分類為：

-   推理模型（大腦）：也就是讓他具備跟人類一樣能夠「推理」、「思考」、「處理資訊」，也是整個架構的核心
    
-   可執行工具（手）：要能夠抓取世界，跟真實世界做互動（API、資料庫、搜尋引擎等），讓代理能夠具備行動能力。
    
-   協調層（神經系統）：管理規劃、記憶（狀態）與推理策略的執行流程。總之就是負責規劃與流程的。
    
-   部署（身體和腳）：將 Agent 託管於伺服器，使其成為可擴展、安全的服務。
    

核心思維轉變：

-   **從磚匠變導演**：傳統開發者像「磚匠」，精確定義邏輯步驟；Agent 開發者則像「導演」，設定場景（指令）、選擇演員（工具）並提供背景（數據）。
    
-   **上下文工程 (Context Engineering)**：從prompt engineering -> context engineering。這被視為 Agent 開發的核心，旨在透過精確管理模型的注意力來達成目標 。
    

Context Engineering很重要，我記得最近Claude也推出了Skills，就是在搞這問題：[agentskills](https://agentskills.io/home)

核心來說，代理運作在一個持續循環的過程來達成任務：

1.  獲取任務：流程由一個具體、高層次的目標啟動，任務可能由使用者提供，也可能由自動觸發器觸發（例如，收到新的高優先客戶工單）
    
2.  掃描/描述場景：智能體感知其環境以收集上下文資訊。「使用者的情球是什麼？說了什麼？」、「我的短期記憶中有什麼訊息？我是否已經嘗試過執行此任務？用戶上週是否提供給我指導？」、「我可以從我的工具（例如日曆、資料庫或者API）中存取哪些內容？」
    
3.  思考：這是代理的核心「思考」循環，由推理模型驅動。代理分析任務（步驟1）與場景（步驟2），並制定計劃。這是一系列推理：「要預定行程，首先需要知道團隊成員有哪些。將使用啥工具，然後幹嘛等等」
    
4.  執行動作：編排執行計劃的一個具體步驟。選擇合適的呼叫工具，這是代理自身內部推理之外對外在世界採取行動。
    
5.  觀察與迭代：代理觀察期操作的結果，然後繼續循環下一步。
    

![Screenshot 2025-12-28 at 3.59.40 PM.png](https://raw.githubusercontent.com/IntensiveCoLearning/GoogleAIAgent25Days/main/assets/Toby1009/images/2025-12-28-1766908796355-Screenshot_2025-12-28_at_3.59.40_PM.png)

接著將Agent系統分個等級（Taxonomy）：

-   Level 0（核心推理系統）：純模型，依賴訓練數據，無即時資訊，優勢在於很好解釋「既定的概念」
    
-   Level 1（連接型問題解決者）：具備工具使用能力（如RAG或搜尋API），可獲取即時數據，也是架構中的「手」，解決的不再只是靜態問題，而是擁有連結世界的能力。
    
-   Level 2（戰略型問題解決者）：能處理複雜、多步驟的計畫與情境工程（Context Engineering），可以提供多樣化複雜的主動任務。
    
-   Level 3（協作式多代理系統）：像人類組織一樣，由不同專業的Agent組成團隊協作。
    
-   Level 4（自我演進系統）：能識別自身能力差距，自主建立新工具或新Agent
    

![Screenshot 2025-12-28 at 5.50.49 PM.png](https://raw.githubusercontent.com/IntensiveCoLearning/GoogleAIAgent25Days/main/assets/Toby1009/images/2025-12-28-1766915467088-Screenshot_2025-12-28_at_5.50.49_PM.png)

為啥要給Agent系統分等級？主要是為了讓開發者、架構師或產品負責人在面對複雜技術環境時，能有一套標準化的框架來進行決策與規劃。總之就是知道系統架構該如何建構、演進以及管理。

有一個有意思的點是做出「超級代理」沒那麼高效，採用「專家團隊」的方法比較好，與人類組織相似，將複雜任務接割成子任務，每個任務都分配給專門的、專業的AI Agent。

![Screenshot 2025-12-28 at 5.51.26 PM.png](https://raw.githubusercontent.com/IntensiveCoLearning/GoogleAIAgent25Days/main/assets/Toby1009/images/2025-12-28-1766915543600-Screenshot_2025-12-28_at_5.51.26_PM.png)

Vertex AI Agent Engine支援Runtime和平台上的所有其他內容。

![Screenshot 2025-12-28 at 5.54.21 PM.png](https://raw.githubusercontent.com/IntensiveCoLearning/GoogleAIAgent25Days/main/assets/Toby1009/images/2025-12-28-1766915681745-Screenshot_2025-12-28_at_5.54.21_PM.png)

在測試方面，不同於傳統軟體開發的測試方式：Devops、MLOps、GenAIOps

AgentOps（不可預測的結構化方式）將不可預測性從一個弱點，轉變成受管理、可衡量且可靠的點。（主要是Agent具備隨機性，需要不同方式）是DevOps和MLOps的演變

![Screenshot 2025-12-28 at 4.34.03 PM.png](https://raw.githubusercontent.com/IntensiveCoLearning/GoogleAIAgent25Days/main/assets/Toby1009/images/2025-12-28-1766910851636-Screenshot_2025-12-28_at_4.34.03_PM.png)

有以下幾種衡量與方式解：

-   衡量重要因素（KPI），就像A/B測試那樣，要讓Agent知道啥是更好？好的標準是啥？
    
-   品質不適用「正確」或「失敗」決定，使用LM Judge
    
-   指標驅動開發
    
-   使用OpenTelemetry Traces來debug
    
-   珍惜人類反饋，像是使用者提交的錯誤報告，或者倒讚啥的，來建立一個新的、永久的測試案例
    

AI要有用，很直覺的就是給予對方Power/權利，但也增加了風險，所以不能僅僅依賴AI模型的判斷，因為它可以被提示注入等技術所操縱，最好的方式是混合式、防禦式的深度方法。

-   第一層：傳統、確定的守護欄組成 - 一組硬編碼的規則，作為模型推理之外的保安瓶頸。可能是一個政策引擎，可阻止任何超過$100的購買，或需要在代理與外部API互動前取得用戶明確確認。這層提供可預測、可審計。給代理權利硬性限制。
    
-   第二層利用基準推論防禦，使用AI來保護AI。這包括訓練模型使其更能抵抗攻擊（對抗性訓練）以及使用，更小、專業化的「保護模型」，這些模型可以在執行前所提出的激化，標示出潛在的高風險或違反政策的步驟，以供審查。
    

在傳統的安全模型中，有人類使用者可能會使用OAuth或SSO，也有使用IAM或服務帳戶的服務。

代理人增加了第三類原則。 代理不僅僅是一個程式；它是一個自主的行為者，一種需要自己可驗證身份的新型原則。 就像向員工發放身份證一樣，平臺上的每個代理都必須獲得安全、可驗證的「數字護照」。 這位代理人身份與呼叫它的使用者和構建它的開發人員的身份不同。 這是我們必須如何處理企業身份和訪問管理（IAM）的根本性轉變。

細緻的顆粒度是必須的，不然造成的破壞性很大，讓我想到之前的「[**Google Antigravity just deleted the contents of my whole drive.**](https://www.reddit.com/r/google_antigravity/comments/1p82or6/google_antigravity_just_deleted_the_contents_of/)」

![Screenshot 2025-12-28 at 4.48.08 PM.png](https://raw.githubusercontent.com/IntensiveCoLearning/GoogleAIAgent25Days/main/assets/Toby1009/images/2025-12-28-1766911695427-Screenshot_2025-12-28_at_4.48.08_PM.png)

利用限制訪問的策略 ：

策略是一種授權形式（AuthZ），與身份驗證（AuthN）不同。 通常，策略限制了委託人的能力；例如，「營銷使用者只能訪問這27個API端點，不能執行刪除命令。」 當我們開發代理時，我們需要對代理、他們的工具、其他內部代理、他們可以共享的上下文和遠端代理應用許可權。 這樣想：如果您將所有API、資料、工具和代理新增到系統中，那麼您必須限制對完成工作所需的功能的子集的訪問。 這是建議的方法：應用最小特權原則，同時保持上下文相關性。

ADK Agent的安全：

隨著身份和政策的核心原則的確立，保護使用代理開發工具包（ADK）構建的代理成為透過程式和配置應用這些概念的實際練習。 如上所述，該過程需要明確定義身份：使用者帳戶（例如OAuth）、服務帳戶（執行程式）、代理身份（使用授權）。 身份驗證處理完畢後，下一層防禦涉及建立政策來限制對服務的訪問。 這通常在API治理層完成，以及支援MCP和A2A服務的治理。 下一層是在您的工具、模型和子代理中構建護欄，以執行策略。 這確保了無論LM的原因或惡意提示可能暗示什麼，工具本身的邏輯都會拒絕執行不安全或非策略的操作。 這種方法提供了一個可預測和可審計的安全基線，將抽象的安全策略轉化為具體、可靠的程式。

![Screenshot 2025-12-28 at 4.57.35 PM.png](https://raw.githubusercontent.com/IntensiveCoLearning/GoogleAIAgent25Days/main/assets/Toby1009/images/2025-12-28-1766912263121-Screenshot_2025-12-28_at_4.57.35_PM.png)

如果正在建立一兩個代理，那關心的在於安全;如果正在建立許多代理，那必須設計系統來處理。

這就是量變引起的質變（Ｘ

Agent本身也是一個新的攻擊向量，惡意者可以嘗試提示詞注入來劫代理程式，或數據中毒來損毀它用於訓練貨RAG的信息。

如果Agent的限制不夠嚴格，可能會無意中在其回應中洩漏敏感客戶資訊或專有信息。

需要提供深度防禦策略減輕風險，確保企業專有信息不會用於訓練基礎模型，並且受到像VPC服務控制這樣的保護，對輸入和輸出過濾，並且提供契約保障，例如對於訓練數據和知識產權的賠償。

需要有個維護交通的，提供所有代理城市交通使用

代理程式對工具的呼叫（透過MCP），代理程式之間的合作（透過A2A），以及直接對LM的推論請求。

透過位於這個關鍵的交匯點，一個組織可以檢查、路由、監控和管理每一個互動。

-   執行政策時執行：作為實施架構的瓶頸安全性。負責處理驗證和授權。集中執行提供了一個「單一視窗」，這將和互不相關的代理程式和工作流程轉變為透明且可核閱的系統。
    
-   中央集權管理：為了有效執行政策，閘道需要一個事實來源。這由中央登記表提供-一個用於代理程式的企業應用商店。此登記能夠發現並重用現有資產，防止重複性工作，同時提供管理完整的清單。
    

更重要的是，它讓代理程式和工具擁有正式的生命週期，允許在發布前進行安全審查、版本控制，以及建立細粒度的政策來規定哪些營運單位可以存取哪些代理。

企業及代理必須同時可靠且具有成本效益

一個代理的表現會隨時間退化-被稱為「老化」，導致效用和信任損失。（老化有可能是過時或者Context windows太多，這也是Claude Skills有提到要解決的）

手動更新一個龐大的代理陣列以跟上這些變化是不經濟且換慢的，更好的方式是設定可以自學和進化的agent，透過最少的工程努力來提高他們的工作品質。

如何自我進化？

學習過程由多種資訊來源驅動：

-   執行時經驗：代理從執行時產生的工作中學習，例如會畫紀錄，痕跡，以及記憶，他們捕捉成功、失敗、工具互動和決策。
    
-   外部信號：例如更新的企業政策、公共監管指南或其他代理人的批評
    

最成功的適應技術可分為兩種類別：

-   增強情境工程：系統持續改進其提示、少樣本範例，以及從記憶中取得的資訊。
    
-   工具優化和創造：代理的推理能識別其能力並行動以填補他們。
    

整理一下生產環境下的幾點關鍵考量：

-   **Agent Ops**：因 Agent 具備隨機性，傳統測試不再適用，需導入「LM 評審 (LM as Judge)」與 OpenTelemetry 追蹤來確保質量 。
    
-   **安全性 (Security)**：採「防禦深度」策略，結合傳統硬性護欄（Hardcoded rules）與 AI 輔助防禦（如 Model Armor）。
    
-   **身分識別 (Identity)**：為 Agent 建立獨立的數位身分（如 SPIFFE 標準），並實施最小權限原則 。
    
-   **互操作性 (Interoperability)**：透過 **A2A 協定**（Agent-to-Agent）讓不同團隊開發的專業 Agent 能夠標準化地溝通與發現 。
    

目前的前沿範例：

-   **Google Co-Scientist**：由多代理組成的生態系統，用於加速科學研究、產生並評估科學假設 。
    
-   **AlphaEvolve**：能夠自主發現並優化數學與計算機科學演算法的系統 。
    
-   **Agent Gym**：一個離線的模擬環境，讓 Agent 在不影響生產環境的情況下進行試錯與學習優化 。
    

## 安裝環境啥的

先來看看有啥資源好了：

-   [Agent Development Kit（ADK）](https://google.github.io/adk-docs/)：ADK是一個靈活、模塊化的框架，主要用於開發與部署AI Agent
    
-   [ADK中文文檔](https://adk.wiki/)
    
-   [Advent of Agents 2025官網](https://adventofagents.com/)
    
-   [Advent of Agents 2025大神筆記](https://github.com/anxiong2025/25-Day-Agents-Course-by-Google?tab=readme-ov-file)
    
-   [Vertex AI Agent Engine](https://docs.cloud.google.com/agent-builder/agent-engine/overview)：是Vertex AI平台的一部分，讓開發人員在正式環境中部署、管理及調度 AI 代理，Agent Engine 會處理基礎架構，以便在正式環境中調度代理，讓您專心打造應用程式。
    
-   [agent-starter-pack](https://github.com/GoogleCloudPlatform/agent-starter-pack)：**一個 Python 包，為 Google Cloud 上的 GenAI 代理提供**生產就緒模板，\*\*專注於您的代理邏輯—入門包提供了其他一切：基礎架構、CI/CD、可觀測性和安全性。
    
-   [Google Codelab](https://codelabs.developers.google.com/?hl=zh-tw)：Google Developers Codelabs 提供引導式教學課程，讓您親身體驗程式設計。大多數程式碼研究室都會逐步引導您建構小型應用程式，或者為現有應用程式新增功能
    
-   [Advent of Agents 2025我的中文翻譯Notion](https://www.notion.so/Google-25-AI-Agent-2d26fba5a2d38037ad5dcb5141935cc2?source=copy_link)
<!-- DAILY_CHECKIN_2025-12-28_END -->
<!-- Content_END -->
